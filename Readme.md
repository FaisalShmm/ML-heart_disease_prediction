# Heart Disease Prediction Using Machine Learning

### Problem Statement

Ah, the heart—the quintessential symbol of love, life, and, unfortunately, disease. Cardiovascular diseases are the leading cause of death worldwide. Our mission, should we choose to accept it, is to predict the presence of heart disease using a bunch of numbers and some fancy algorithms. Because who needs a medical degree when you have machine learning, right?

---



#### [Dataset](https://www.kaggle.com/datasets/mexwell/heart-disease-dataset?select=heart_statlog_cleveland_hungary_final.csv)

It contains 13 attributes such as age, sex, chest pain type, and a few other things your doctor might pretend to care about during your annual check-up. The target variable indicates whether the patient has heart disease (1) or is blissfully ignorant of their impending doom (0).

---

### Project Overview

The goal of this project is to predict the presence of heart disease in patients based on various health metrics. Think of it as your personal fortune-teller, but for your heart. The dataset includes features like age, sex, chest pain type, resting blood pressure, cholesterol levels, and more. The target variable is binary: 0 (no disease) and 1 (disease).

---

## Steps Involved

* **Data Cleaning and Preprocessing**
  
  * Handling missing values, duplicates, and outliers like a data janitor on caffeine.
  * Encoding categorical variables, because computers don’t understand words, only numbers.
  * Scaling features to make sure everything is on the same playing field.
* **Exploratory Data Analysis (EDA)**
  
  * Univariate, bivariate, and multivariate analysis—fancy terms for "let’s see what this data looks like."
  * pair plots for feature relationships, because who doesn’t love a good visual?
* **Model Training and Evaluation**
  
  * Using various models including Logistic Regression, SVC, Decision Trees, Random Forest, Gradient Boosting, KNN, Naive Bayes, and XGBoost.
* **Optimization**
  
  * Hyperparameter tuning using GridSearchCV or RandomizedSearchCV, because good isn’t good enough.
  * Evaluating the best model based on cross-validation scores.

---

### Models used

* **Logistic Regression** (Scikit-learn)
* **Naive Bayes** (Scikit-learn)
* **Support Vector Machine (Linear)** (Scikit-learn)
* **K-Nearest Neighbors** (Scikit-learn)
* **Decision Tree** (Scikit-learn)
* **Random Forest** (Scikit-learn)
* **XGBoost** (Scikit-learn)

---

## Accuracy Achieved:**

**93.28 % (Random Forest)**

---

> May your journey in machine learning be as steady as a healthy heartbeat!







